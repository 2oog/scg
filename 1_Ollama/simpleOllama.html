<!doctype html>
<html lang="en">

<head>
    <!-- Head: metadata, title, CSS/JS includes for Bootstrap and marked -->
    <meta charset="utf-8" />
    <title>Ollama Stream Viewer</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

    <style>
        /* Styles: layout and basic visuals
           - full-height setup
           - left column sizing (controls & prompt)
           - right viewer styling (scrollable, background)
           - code block wrapping */
        html,
        body {
            height: 100%;
        }

        #leftCol {
            min-height: 100vh;
        }

        #prompt {
            min-height: 0;
        }

        #viewer {
            height: 100vh;
            overflow: auto;
            padding: 1rem;
            background: #0f172a0d;
            border-left: 1px solid rgba(0, 0, 0, .085);
        }

        pre code {
            white-space: pre-wrap;
            word-break: break-word;
        }
    </style>
</head>

<body>
    <div class="container-fluid">
        <div class="row g-0">
            <!-- Left column: model selector + prompt + controls -->
            <div id="leftCol" class="col-12 col-md-6 d-flex flex-column p-3">
                <!-- Model selector: populated from local Ollama models via API -->
                <div class="mb-3">
                    <label for="modelSelect" class="form-label">Ollama model</label>
                    <select id="modelSelect" class="form-select" aria-label="Ollama model"></select>
                </div>

                <div class="d-flex flex-column flex-grow-1">
                    <!-- Prompt area: textarea where user types the prompt -->
                    <label for="prompt" class="form-label">Prompt</label>
                    <textarea id="prompt" class="form-control flex-grow-1"
                        placeholder="Type your prompt here..."></textarea>
                    <div class="mt-3 d-flex gap-2">
                        <!-- Controls:
                             - Send: starts streaming the model response
                             - Stop: aborts an in-flight stream
                             - status: shows streaming/error state -->
                        <button id="sendBtn" class="btn btn-primary">Send</button>
                        <button id="stopBtn" class="btn btn-outline-secondary" disabled>Stop</button>
                        <div id="status" class="ms-auto text-muted small d-flex align-items-center"></div>
                    </div>
                </div>
            </div>

            <!-- Right column: viewer displays streamed output rendered as Markdown -->
            <div class="col-12 col-md-6">
                <div id="viewer" class="bg-light">
                    <em class="text-muted">Streamed output will appear here…</em>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Script: logic to load models, start/stop streaming, and render Markdown

        // Constants: base URL and endpoint paths for local Ollama daemon
        const OLLAMA_BASE = 'http://localhost:11434';
        const tagsUrl = OLLAMA_BASE + '/api/tags';
        const chatUrl = OLLAMA_BASE + '/api/chat';

        // DOM elements: references to UI controls we will update/interact with
        const modelSelect = document.getElementById('modelSelect');
        const promptEl = document.getElementById('prompt');
        const viewer = document.getElementById('viewer');
        const sendBtn = document.getElementById('sendBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusEl = document.getElementById('status');

        // State: controller to abort fetch, and flag if streaming is active
        let controller = null;
        let streaming = false;

        // loadModels(): fetch available local models and populate the <select>
        async function loadModels() {
            modelSelect.innerHTML = '<option value="">Loading models…</option>';
            try {
                const res = await fetch(tagsUrl);
                if (!res.ok) throw new Error('Failed to fetch models');
                const data = await res.json();
                const models = (data && data.models) ? data.models : [];
                if (!models.length) {
                    modelSelect.innerHTML = '<option value="">No local models found</option>';
                    return;
                }
                modelSelect.innerHTML = models
                    .map(m => `<option value="${m.name}">${m.name}</option>`)
                    .join('');
            } catch (err) {
                modelSelect.innerHTML = '<option value="">Error loading models</option>';
                console.error(err);
            }
        }

        // setUIBusy(busy): enable/disable UI while streaming to prevent concurrent requests
        function setUIBusy(busy) {
            streaming = busy;
            sendBtn.disabled = busy;
            stopBtn.disabled = !busy;
            modelSelect.disabled = busy;
            promptEl.disabled = busy;
            statusEl.textContent = busy ? 'Streaming…' : '';
        }

        // appendMarkdown(buffer): render accumulated Markdown into the viewer and auto-scroll
        function appendMarkdown(buffer) {
            try {
                viewer.innerHTML = marked.parse(buffer);
                viewer.scrollTop = viewer.scrollHeight;
            } catch (e) {
                console.error('Markdown parse error:', e);
            }
        }

        // streamChat(model, userPrompt):
        // - aborts any previous request
        // - posts to /api/chat with stream=true
        // - reads streaming response chunks, accumulates text, renders as Markdown
        async function streamChat(model, userPrompt) {
            // Abort any in-flight request
            if (controller) controller.abort();
            controller = new AbortController();
            const { signal } = controller;

            setUIBusy(true);
            viewer.innerHTML = '';
            let acc = '';

            try {
                const res = await fetch(chatUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model,
                        messages: [{ role: 'user', content: userPrompt }],
                        stream: true
                    }),
                    signal
                });

                if (!res.ok || !res.body) {
                    throw new Error('Failed to start stream');
                }

                const reader = res.body.getReader();
                const decoder = new TextDecoder();

                while (true) {
                    // Read loop: decode incoming bytes, split into lines (each line is JSON)
                    const { value, done } = await reader.read();
                    if (done) break;
                    const chunk = decoder.decode(value, { stream: true });

                    const lines = chunk.split('\n').filter(Boolean);
                    for (const line of lines) {
                        try {
                            const data = JSON.parse(line);

                            if (data.done) {
                                setUIBusy(false);
                                break;
                            }

                            const delta =
                                (data.message && typeof data.message.content === 'string')
                                    ? data.message.content
                                    : (typeof data.response === 'string' ? data.response : '');

                            if (delta) {
                                acc += delta;
                                appendMarkdown(acc);
                            }
                        } catch (e) {
                            // Non-JSON line (ignore)
                        }
                    }
                }
            } catch (err) {
                if (err.name !== 'AbortError') {
                    console.error(err);
                    statusEl.textContent = 'Error';
                }
            } finally {
                setUIBusy(false);
            }
        }

        // Event handlers:
        // - Send: validate inputs and call streamChat
        // - Stop: abort the controller to halt streaming
        sendBtn.addEventListener('click', () => {
            const model = modelSelect.value.trim();
            const userPrompt = promptEl.value.trim();
            if (!model) {
                alert('Please choose a model first.');
                return;
            }
            if (!userPrompt) {
                alert('Please enter a prompt.');
                return;
            }
            streamChat(model, userPrompt);
        });

        stopBtn.addEventListener('click', () => {
            if (controller) controller.abort();
            setUIBusy(false);
        });

        // Initialize: load model list on page load
        loadModels();
    </script>
</body>

</html>